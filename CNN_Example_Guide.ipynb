{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e75fc11f",
   "metadata": {},
   "source": [
    "### Алгоритм обучения нейронной сети класса CNN\n",
    "\n",
    "- Подготовка и стандартизация данных;\n",
    "- Моделирование, подбор параметров нейронной сети;\n",
    "- Подбор параметров обучения;\n",
    "- Обучение;\n",
    "- Оценка качества обучения. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cc4006",
   "metadata": {},
   "source": [
    "### Описание кейса\n",
    "\n",
    "Проведем обучение сверточной нейронной сети для задач распознавания рукописного текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ae5570",
   "metadata": {},
   "source": [
    "### Подготовка и стандартизация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ed5a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установим необходимые модули для обеспечения процесса:\n",
    "import keras\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist # библиотека базы выборок Mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# ﻿import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59c4648",
   "metadata": {},
   "source": [
    "### Подготовка и стандартизация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b27c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установим необходимые модули для обеспечения процесса:\n",
    "import keras\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist # библиотека базы выборок Mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# ﻿import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2841b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# За тренировочной и тестовой выборкой адресуем к библиотеке mnist \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55f4477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проведем стандартизацию входных данных\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "# Преобразуем вектор класса (целые числа) в двоичную матрицу класса (нужно для categorical_crossenthropy)\n",
    "y_train_cat = keras.utils.to_categorical(y_train, 10) \n",
    "y_test_cat = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eebf5f3",
   "metadata": {},
   "source": [
    "В библиотеке Keras сверточная нейронная сеть принимает тензор либо в формате ``` batch, channels, rows, cols``` или же в формате ``` batch, rows, cols, channels``` (размерность батчей, число строк, число столбцов у входного изображения или карты признаков, число каналов: если монохромное, то = 1, если цветное, то = 3, если карта признаков, то = числу фильтров). По умолчанию сейчас тензоры имеют формат ``` batch, rows, cols``` Функция ```np.expand_dims``` преобразует входные тензоры при помощи добавления оси размерности (0,1,2... n) Таким образом добавляя ось ```axis = 3``` мы добавляем в описание тензора недостающий ```...channels```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5d3b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем тензоры в читаемый нейронной сетью формат ``` batch, rows, cols, channels```\n",
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "x_test = np.expand_dims(x_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fd5150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим размерность обучающей выборки матрицы входных значений\n",
    "print( x_train.shape ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8bbf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "```60000``` количество изображений на вход\n",
    "```28, 28, 1``` размерность изображения и количество цветовых каналов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f219bd6",
   "metadata": {},
   "source": [
    "### Моделирование, подбор параметров нейронной сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68acd2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установим необходимые модули для обеспечения процесса:\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense # Модуль описания слоев полносвязной нейронной сети (классификации признаков)\n",
    "from tensorflow.keras.layers import Flatten # Модуль стандартизации (выравнивания) входных данных\n",
    "from tensorflow.keras.layers import Conv2D # Модуль описания слоев свёрточной нейронной сети (извлечение признаков)\n",
    "from tensorflow.keras.layers import MaxPooling2D # Модуль описания слоев субдискретизации (MaxPooling)\n",
    "from tensorflow.keras.layers import Dropout # Модуль отсеивания (регуляризация)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c55a7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установим модуль для сохранения модели:\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764b7b40",
   "metadata": {},
   "source": [
    "Гипперпараметры ```Conv2D```:\n",
    "- ```filters``` = число ядер импульксного отклика (каналов, фильтров)\n",
    "- ```kernel_size``` = размер ядра\n",
    "- ```padding``` = масштаб выходной карты признаков ``` same``` = такой же ```valid``` = с уменьшением\n",
    "- ```input shape``` = формат фрагмента изображения в одной свёртке\n",
    "\n",
    "Гипперпараметры ```MaxPooling2D```:\n",
    "- ```Pool size``` = размер окна, в котором выбираются максимальные значения\n",
    "- ```Strides``` = шаг сканирования по осям плоскости. По умолчанию = в 1 пиксел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e5ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определим модель и гипперпараметры модели:\n",
    "model = keras.Sequential([ # задаем модель для простого стека слоев (каркас с одним входным и выходным тензором)\n",
    "    \n",
    "    # Опишем модуль извлечения признаков (Cверточные C и слои субдискретизации S)\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(28, 28, 1)), # Параметры первого сверточного слоя (C1)\n",
    "    MaxPooling2D((2, 2), strides=2), # Параметры первого слоя субдискретизации (S1)\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'), # Параметры второго сверточного слоя (С2)\n",
    "    MaxPooling2D((2, 2), strides=2), # Параметры второго слоя субдискретизации (S2)\n",
    "    Flatten(), # преобразование тензора в вектор\n",
    "    \n",
    "    # Опишем модуль классификации и вывода (F слои полносвязной сети)\n",
    "    Dense(128, activation='relu'), # Параметры скрытого слоя (F1)\n",
    "    Dense(10,  activation='softmax') # Параметры выходного скрытого слоя (F1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b4a603",
   "metadata": {},
   "source": [
    "Поясним:\n",
    "_Первая итерация извлечения признаков:\n",
    "- ```Conv2D```(```32``` фильтра, размером ядра ```3x3```), масштаб выходного значения = ```такой же```, функция активация ядра = ```relu```, формат входного изображения ```28х28``` c ```1``` цветовым каналом\n",
    "- ```MaxPooling2D```(размер окна ```2x2```), с шагом сканирования ```2``` пиксела (чтобы не пересекалась)\n",
    " \n",
    "_Вторая итерация извлечения признаков:\n",
    "- ```Conv2D```(```64``` фильтра...) остальное все идентично первой итерации. \n",
    "\n",
    "_После первой итерации размерность выходных значений уменьшилась вдвое и стала ```14x14x32```. После второй получаем тензор размерностью ```7x7``` и ```64``` каналла. ```Flatten``` преобразует этот тензор в вектор для последующей подачи на полносвязную нейронную сеть.  \n",
    "\n",
    "_Классификация признаков:\n",
    "- Скрытый слой задаем ```128``` нейронов,\n",
    "- Выходной слой задаём ```10``` нейронов. (Почему ```softmax```???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557b0474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выводим структуру модели в блокнот\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efcbec2",
   "metadata": {},
   "source": [
    "Поясним:_\n",
    "- Слой C1 ```conv2d```содержит ```320``` коэффициентов. Откуда эти цифры: ```32``` фильтра размером ```3x3 = 9``` пикселя + ```1``` bias = ```10```, ```32 x 10 = 320```\n",
    "\n",
    "- Слой C2 ```conv2d_1```содержит ```18496``` коэффициентов. Откуда эти цифры: ```32``` фильтра размером ```3x3 = 9``` пикселя + ```1``` bias = ```10```, и умножаем еще на ```64``` фмльтра второго сверточного слоя```(3 x 3 x 32 + 1) * 64  = 18496```\n",
    "\n",
    "- Слой F1 ```dense_2```содержит ```401536``` коэффициентов. Откуда эти цифры: подаваемый тензор на вход имеет формат ```7x7x64 + 1 = 3137``` пикселя, причем каждый из них связан с ```128``` коэффициентами изображения. Итого получаем ```3137 x 128 = 401536```\n",
    "\n",
    "- Слой F1 ```dense_3```содержит ```1290``` коэффициентов. Откуда эти цифры: на выходной слой подаются ```128 + 1```  значений, которые связаны с ```10``` нейронами выходного слоя. Итого получаем ```129 * 10 = 1290```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177e2489",
   "metadata": {},
   "source": [
    "### Подбор параметров обучения\n",
    "\n",
    "В отличие от процессов обучения простых нейронных сетей, итерации обучения в Deep Learning занимают сравнительно продолжительное время. Происходит это из-за большого количества коэффициентов. Однако количество эпох сокращено на порядок. Задем параметры качества: инициализации входных значений весов, а также критерии качества "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13cce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаём параметры обучения\n",
    "model.compile(optimizer='adam', # Метод оптимизации поиска начальных значений оставляем adam. в укачестве альтернативы: 'sgd'\n",
    "             loss='categorical_crossentropy', # Функция потерь категориальная кросс-энтропия, т.к. у нас больше классов\n",
    "             metrics=['accuracy']) # Метрика качества = точность, т.к. классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a135a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Определим критерии наилучшей модели, которая пойдёт в продакшен после обучения: \n",
    "```monitor``` = для отслеживания показателей проверки ```'val_loss'```\n",
    "```verbose``` = показатель уровня логгирования модели ```'1'```\n",
    "```save_best_only``` = сохраняем только лучшую модель ```'true'```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c75cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определим, какие версии обученных моделей будем сохранять\n",
    "filename = 'model.h15' # создадим checkpoint для сохранения модели в каждм цикле обучения\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adc64a1",
   "metadata": {},
   "source": [
    "### Обучение нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b77d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "Продолжительность обучения будет составлять ```5``` эпох:\n",
    "Размер выборки валидации определим как ```20%```:\n",
    "Изменение конфигурации весов будем проводить каждые ```32``` тензора: по количеству карт признаков на входной свертке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e683dd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-2-3 Поехали! (старт обучение на обучающей выборке)\n",
    "his = model.fit(x_train, y_train_cat, batch_size=32, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4e587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оцениваем качество обученной модели на тестовой выборке \n",
    "print('***** train')\n",
    "model.evaluate(x_test, y_test_cat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
